import streamlit as st
# LangChain ç›¸é—œçš„å°å…¥
from langchain_community.document_loaders import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models import ChatOllama

# region --- Streamlit è¨­å®š ---
st.set_page_config(page_title="æ™ºèƒ½åŠ©ç†", layout="centered", initial_sidebar_state="auto")
st.title("æ™ºèƒ½åŠ©ç†")
st.markdown("---")
temperature = st.slider("AI temperature (æ•¸å€¼è¶Šå¤§ï¼ŒAIæä¾›è¶Šç†±æƒ…çš„æœå‹™æ…‹åº¦)", max_value=1.0, min_value=0.0, step=0.01, value=0.0)
# é è¨­çš„çŸ¥è­˜åº«æ–‡æœ¬ç¯„ä¾‹ (æ–¹ä¾¿ä½¿ç”¨è€…åƒè€ƒ)
ph = """æœ¬å…¬å¸å°ˆé–€éŠ·å”®é«˜å“è³ªçš„æœ‰æ©Ÿå’–å•¡è±†, æˆ‘å€‘åªå¾å·´è¥¿ã€å“¥å€«æ¯”äºå’Œè¡£ç´¢æ¯”äºçš„å…¬å¹³è²¿æ˜“è¾²å ´é€²å£å’–å•¡è±†.æˆ‘å€‘çš„çƒ˜ç„™å¸«å‚…æ“æœ‰è¶…é20å¹´çš„ç¶“é©—, ç¢ºä¿æ¯ä¸€æ‰¹å’–å•¡è±†éƒ½èƒ½å®Œç¾çƒ˜ç„™, å¸¶å‡ºå…¶ç¨ç‰¹çš„é¢¨å‘³.é¡§å®¢æœå‹™æ˜¯æˆ‘å€‘çš„é¦–è¦ä»»å‹™, æ‰€æœ‰è¨‚å–®åœ¨24å°æ™‚å…§å‡ºè²¨, ä¸¦æä¾›7å¤©å…§ç„¡æ¢ä»¶é€€è²¨æœå‹™.ç›®å‰æˆ‘å€‘çš„ç†±éŠ·ç”¢å“æœ‰ï¼šå·´è¥¿é™½å…‰å’–å•¡è±† (ä¸­åº¦çƒ˜ç„™, å¸¶æœ‰å …æœé¦™æ°£). å“¥å€«æ¯”äºé»ƒé‡‘å’–å•¡è±† (æ·±åº¦çƒ˜ç„™,å£æ„Ÿæ¿ƒéƒ) å’Œè¡£ç´¢æ¯”äºèŠ±åœ’å’–å•¡è±† (æ·ºåº¦çƒ˜ç„™ï¼Œå¸¶æœ‰èŠ±æœé¦™)ã€‚
        æˆ‘å€‘ä¹Ÿæä¾›å’–å•¡å™¨å…·å’Œå’–å•¡ç ”ç£¨æ©Ÿçš„éŠ·å”®ï¼Œä¸¦ä¸”å®šæœŸèˆ‰è¾¦å’–å•¡å“é‘‘æœƒå’Œçƒ˜ç„™èª²ç¨‹.æ‰€æœ‰ç”¢å“çš„éŠ·å”®åˆ©æ½¤çš„5%å°‡æè´ˆçµ¦å…¨çƒçš„å’–å•¡è¾²æ‰¶åŠ©åŸºé‡‘.æˆ‘å€‘æ¥å—Visaã€MasterCardå’ŒAmexä¿¡ç”¨å¡æ”¯ä»˜.å°æ–¼æ‰¹ç™¼è¨‚å–®, æˆ‘å€‘æä¾›ç‰¹æ®Šçš„æŠ˜æ‰£.å…¬å¸ç¸½éƒ¨ä½æ–¼å°åŒ—å¸‚ï¼Œæˆ‘å€‘çš„å®¢æˆ¶æœå‹™ç†±ç·šæ˜¯ (02) 1234-5678ã€‚"""

# è®“ä½¿ç”¨è€…è¼¸å…¥çŸ¥è­˜åº«æ–‡æœ¬
user_context_text = st.text_area(
    label="è«‹åœ¨ä¸‹æ–¹è¼¸å…¥æ‚¨çš„è³‡è¨Šä½œç‚ºçŸ¥è­˜åº«ï¼š",
    value="",  # åˆå§‹å€¼ç‚ºç©º
    height=300,
    placeholder="ä»¥ä¸€é–“å’–å•¡éŠ·å”®å…¬å¸ç‚ºç¯„ä¾‹:\n" + ph  # é¡¯ç¤ºç¯„ä¾‹æç¤º
)

# åˆ¤æ–·æœ€çµ‚ä½¿ç”¨çš„çŸ¥è­˜åº«æ–‡æœ¬ï¼šå¦‚æœä½¿ç”¨è€…è¼¸å…¥ç‚ºç©ºï¼Œå‰‡ä½¿ç”¨é è¨­ç¯„ä¾‹æ–‡æœ¬
final_context_text = ph if len(user_context_text.strip()) == 0 else user_context_text.strip()


# ç”¨æ–¼è¨­å®š RAG ç³»çµ±çš„å‡½æ•¸ï¼ˆä¸å†ç·©å­˜ï¼Œå› ç‚ºçŸ¥è­˜åº«æ˜¯å‹•æ…‹çš„ï¼‰
def setup_rag_system_dynamic(context_text, temp):
    """ è¨­å®šä¸¦è¿”å› RAG ç³»çµ±çµ„ä»¶ (å‘é‡è³‡æ–™åº«, æª¢ç´¢å™¨, LLM, RAGéˆ)ã€‚è©²å‡½æ•¸æœƒæ ¹æ“šå‚³å…¥çš„ context_text å»ºç«‹æ–°çš„çŸ¥è­˜åº«ã€‚"""
    knowledge_file = "company_knowledge_base.txt"  # 0. å°‡æ–‡æœ¬å¯«å…¥ä¸€å€‹è‡¨æ™‚æ–‡ä»¶ï¼Œä»¥ä¾¿ TextLoader è®€å–
    with open(knowledge_file, "w", encoding="utf-8") as f:
        f.write(context_text)
    loader = TextLoader(knowledge_file, encoding="utf-8")  # 1. è¼‰å…¥ä¸¦åˆ†å‰²æ–‡æœ¬
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = text_splitter.split_documents(documents)

    # 2. ç”ŸæˆåµŒå…¥ä¸¦å»ºç«‹å‘é‡è³‡æ–™åº«
    embeddings = OllamaEmbeddings(model="nomic-embed-text")  # è«‹ç¢ºä¿ä½ å·²ç¶“ç”¨ 'ollama pull nomic-embed-text' ä¸‹è¼‰äº†åµŒå…¥æ¨¡å‹
    vectorstore = Chroma.from_documents(chunks, embeddings)  # å»ºç«‹ Chroma å‘é‡è³‡æ–™åº«ã€‚æ¯æ¬¡èª¿ç”¨éƒ½æœƒå‰µå»ºä¸€å€‹æ–°çš„ã€ç¨ç«‹çš„ in-memory è³‡æ–™åº«ã€‚
    retriever = vectorstore.as_retriever()

    # 3. å®šç¾© LLM
    llm = ChatOllama(model="llama3.2", temperature=temp)  # temperature=0 ç¢ºä¿å›è¦†æ›´ç²¾ç¢ºå’Œç©©å®š

    rag_prompt = ChatPromptTemplate.from_messages([  # 4. æ§‹å»º RAG æç¤ºæ¨¡æ¿
        ("system", """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„åŠ©ç†ã€‚è«‹æ ¹æ“šä»¥ä¸‹æª¢ç´¢åˆ°çš„è³‡è¨Šä¾†å›ç­”å•é¡Œã€‚
          å¦‚æœè³‡è¨Šä¸­æ²’æœ‰æåˆ°ï¼Œè«‹ç¦®è²Œåœ°èªªä½ ç„¡æ³•å›ç­”ï¼Œä¸¦é¿å…ç·¨é€ å…§å®¹ã€‚
          \n\næª¢ç´¢åˆ°çš„è³‡è¨Šï¼š\n{context}"""),
        ("human", "{question}")
    ])

    rag_chain_input_mapper = {"context": retriever, "question": RunnablePassthrough()}  # 5. å‰µå»º RAG éˆ
    rag_chain = rag_chain_input_mapper | rag_prompt | llm | StrOutputParser()

    # æ–°å¢çš„æ‘˜è¦å’Œé—œéµå­—æå–éƒ¨åˆ†
    summarize_prompt = ChatPromptTemplate.from_messages([
        ("system", "è«‹æ ¹æ“šä»¥ä¸‹æ–‡æœ¬å…§å®¹ï¼Œç¸½çµå‡ºä¸‰å€‹ä¸»è¦é‡é»ã€‚æ¯å€‹é‡é»è«‹ç”¨æ¢åˆ—å¼å‘ˆç¾ï¼Œä¸”ä¸è¶…é20å€‹å­—ã€‚\n\næ–‡æœ¬å…§å®¹:\n{text}"),
        ("human", "è«‹ç¸½çµã€‚")
    ])
    summarize_chain = {"text": RunnablePassthrough()} | summarize_prompt | llm | StrOutputParser()
    summary = summarize_chain.invoke(context_text)

    keywords_prompt = ChatPromptTemplate.from_messages([
        ("system", "è«‹æ ¹æ“šä»¥ä¸‹æ–‡æœ¬å…§å®¹ï¼Œæå–å‡ºä¸‰å€‹æœ€é‡è¦çš„é—œéµå­—ã€‚è«‹ç”¨é€—è™Ÿåˆ†éš”ã€‚\n\næ–‡æœ¬å…§å®¹:\n{text}"),
        ("human", "è«‹æå–é—œéµå­—ã€‚")
    ])
    keywords_chain = {"text": RunnablePassthrough()} | keywords_prompt | llm | StrOutputParser()
    keywords = keywords_chain.invoke(context_text)

    questions_prompt = ChatPromptTemplate.from_messages([
        ("system", "æ ¹æ“šä»¥ä¸‹æ–‡æœ¬å…§å®¹ï¼Œè¨­æƒ³ä½¿ç”¨è€…å¯èƒ½æœ€æ„Ÿèˆˆè¶£çš„ä¸‰å€‹å•é¡Œã€‚è«‹ç”¨æ¢åˆ—å¼å‘ˆç¾ã€‚\n\næ–‡æœ¬å…§å®¹:\n{text}"),
        ("human", "è«‹æå‡ºå•é¡Œã€‚")
    ])
    questions_chain = {"text": RunnablePassthrough()} | questions_prompt | llm | StrOutputParser()
    questions = questions_chain.invoke(context_text)

    return rag_chain, summary, keywords, questions


def highlight_important_tokens(text, keywords):
    """
    ç”¨ç´…è‰²ç²—é«”æ¨™è¨˜æ–‡æœ¬ä¸­çš„é—œéµå­—ã€‚
    keywords æ‡‰è©²æ˜¯ä¸€å€‹åˆ—è¡¨æˆ–é›†åˆï¼ŒåŒ…å«è¦æ¨™è¨˜çš„é—œéµå­—ã€‚
    """
    highlighted_text = text
    # Split keywords string into a list
    keyword_list = [k.strip() for k in keywords.split(',') if k.strip()]

    for keyword in keyword_list:
        # Using a simple replace. For more robust highlighting (e.g., avoiding partial word matches),
        # you might need regex with word boundaries.
        highlighted_text = highlighted_text.replace(
            keyword, f'<span style="color:red;font-weight:bold;">{keyword}</span>'
        )
    return highlighted_text


# endregion

# region --- åˆå§‹è®Šæ•¸ ---
if "messages" not in st.session_state:  # æ­·å²è¨Šæ¯
    st.session_state.messages = []
if "rag_system_ready" not in st.session_state:  # ç•¶ç³»çµ±æº–å‚™å¥½çš„æ™‚å€™ï¼Œä¹Ÿå°±æ˜¯ä»£è¡¨ä½¿ç”¨è€…å·²ç¶“ç¢ºèªå°‡è³‡æ–™åšåˆå§‹åŒ–ï¼Œæ¥è‘—æ–¹èƒ½é–‹å•Ÿå•ç­”
    st.session_state.rag_system_ready = False
if "rag_chain" not in st.session_state:  # ragéŠæ ¸å¿ƒï¼Œæˆ‘å€‘æ˜¯åˆ©ç”¨ rag_chain.invoke() ä¾†å–å¾— ai è³‡è¨Š
    st.session_state.rag_chain = None
if "initial_kb_loaded" not in st.session_state:  # è¿½è¹¤æ˜¯å¦å·²é¦–æ¬¡è¼‰å…¥çŸ¥è­˜åº«
    st.session_state.initial_kb_loaded = False
if "show_confirm_modal" not in st.session_state:  # æ˜¯å¦é¡¯ç¤ºå†ç¢ºèªæ–¹æ¡†
    st.session_state.show_confirm_modal = False
if "summary_output" not in st.session_state:
    st.session_state.summary_output = ""
if "keywords_output" not in st.session_state:
    st.session_state.keywords_output = ""
if "questions_output" not in st.session_state:
    st.session_state.questions_output = ""
# endregion

# region --- åˆå§‹æŒ‰éˆ• ---
if st.button("åˆå§‹åŒ–/æ›´æ–°çŸ¥è­˜åº«"):  # ç•¶ä½¿ç”¨è€…é»æ“Šæ­¤æŒ‰éˆ•æ™‚ï¼Œæ ¹æ“šç‹€æ…‹æ±ºå®šæ˜¯ç›´æ¥åˆå§‹åŒ–é‚„æ˜¯é¡¯ç¤ºç¢ºèªæ–¹æ¡†
    if not st.session_state.initial_kb_loaded:  # ç¬¬ä¸€æ¬¡é»æ“Šï¼šç›´æ¥åˆå§‹åŒ–çŸ¥è­˜åº«
        if len(final_context_text) == 0:
            st.error("è«‹åœ¨æ–‡å­—å€åŸŸä¸­è¼¸å…¥æ‚¨çš„è³‡è¨Šï¼Œæˆ–ä½¿ç”¨ç¯„ä¾‹æ–‡æœ¬ã€‚")
        else:
            with st.spinner("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–çŸ¥è­˜åº«èˆ‡ AI æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
                try:
                    rag_chain, summary, keywords, questions = setup_rag_system_dynamic(final_context_text, temperature)
                    st.session_state.rag_chain = rag_chain
                    st.session_state.summary_output = summary
                    st.session_state.keywords_output = keywords
                    st.session_state.questions_output = questions
                    st.session_state.rag_system_ready = True
                    st.session_state.initial_kb_loaded = True  # æ¨™è¨˜ç‚ºå·²è¼‰å…¥
                    st.success("ğŸ‰ çŸ¥è­˜åº«èˆ‡ AI æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ç¾åœ¨å¯ä»¥é–‹å§‹æå•äº†ã€‚")
                    st.session_state.messages = []  # æ¸…ç©ºèŠå¤©æ­·å²
                except Exception as e:
                    st.session_state.rag_system_ready = False
                    st.session_state.rag_chain = None
                    st.error(f"åˆå§‹åŒ–å¤±æ•—ï¼š{e}ã€‚è«‹ç¢ºèª Ollama æœå‹™æ­£åœ¨é‹è¡Œä¸”æ¨¡å‹å·²ä¸‹è¼‰ã€‚")
                    st.warning("è«‹ç¢ºä¿æ‚¨å·²å®‰è£ Ollama ä¸¦å·²æ‹‰å–ä»¥ä¸‹æ¨¡å‹ï¼š`nomic-embed-text` å’Œ `llama3.2`ã€‚")
    else:
        st.session_state.show_confirm_modal = True  # å¦‚æœå·²ç¶“åˆå§‹åŒ–éï¼Œå‰‡è·³åˆ° show_confirm_modal ç¢ºèªæ–¹æ¡†é‚è¼¯(ä¸‹æ–¹)
        st.rerun()  # å¼·åˆ¶ Streamlit é‡æ–°åŸ·è¡Œï¼Œä»¥ç«‹å³é¡¯ç¤ºç¢ºèªæ–¹æ¡†
# endregion

# region --- æ–¹æ¡†é‚è¼¯ ---
if st.session_state.show_confirm_modal:  # åªæœ‰ç•¶ st.session_state.show_confirm_modal ç‚º True æ™‚æ‰é¡¯ç¤º
    st.markdown("---")  # åˆ†éš”ç·š
    st.info("â„¹ï¸ æ‚¨å·²ç¶“åˆå§‹åŒ–éçŸ¥è­˜åº«ã€‚å†æ¬¡é»æ“Šè¡¨ç¤ºæ‚¨è¦**æ›´æ–°**çŸ¥è­˜åº«ã€‚")
    st.write("æ˜¯å¦ç¢ºå®šè¦ç”¨ç•¶å‰æ–‡å­—å€åŸŸçš„è³‡è¨Šä¾†æ›´æ–°çŸ¥è­˜åº«ï¼Ÿé€™å°‡æ¸…é™¤ç•¶å‰å°è©±æ­·å²ï¼Œä¸¦ä¸”ç¢ºèªæ‚¨æä¾›çš„è³‡è¨Š**æ˜¯å¦å‰å¾Œæœ‰ç‰´è§¸***ã€‚")
    col_confirm, col_cancel = st.columns(2)  # è¨­ç½®å…©å€‹æŒ‰éˆ•ï¼Œç”¨æ–¼ç¢ºèªæˆ–å–æ¶ˆæ“ä½œ
    with col_confirm:
        if st.button("ç¢ºå®šæ›´æ–°", key="confirm_update_kb_button"):  # é»æ“Šã€Œç¢ºå®šæ›´æ–°ã€æŒ‰éˆ•
            if len(final_context_text) == 0:  # åŸ·è¡ŒçŸ¥è­˜åº«æ›´æ–°çš„é‚è¼¯
                st.error("è«‹åœ¨æ–‡å­—å€åŸŸä¸­è¼¸å…¥æ‚¨çš„è³‡è¨Šï¼Œæˆ–ä½¿ç”¨ç¯„ä¾‹æ–‡æœ¬ã€‚")
                st.session_state.show_confirm_modal = False  # å‡ºéŒ¯æ™‚éš±è—æ–¹æ¡†
                st.rerun()  # å¼·åˆ¶é‡æ–°åŸ·è¡Œä»¥æ›´æ–°UI
            else:
                with st.spinner("ğŸ”„ æ­£åœ¨æ›´æ–°çŸ¥è­˜åº«èˆ‡ AI æ¨¡å‹ï¼Œè«‹ç¨å€™..."):
                    try:
                        rag_chain, summary, keywords, questions = setup_rag_system_dynamic(final_context_text, temperature)
                        st.session_state.rag_chain = rag_chain
                        st.session_state.summary_output = summary
                        st.session_state.keywords_output = keywords
                        st.session_state.questions_output = questions
                        st.session_state.rag_system_ready = True
                        st.success("âœ… çŸ¥è­˜åº«å·²æˆåŠŸæ›´æ–°ï¼")
                        st.session_state.messages = []  # æ¸…ç©ºèŠå¤©æ­·å²
                        st.session_state.show_confirm_modal = False  # éš±è—ç¢ºèªæ–¹æ¡†
                        st.rerun()  # å¼·åˆ¶é‡æ–°åŸ·è¡Œä»¥æ›´æ–°UI
                    except Exception as e:
                        st.session_state.rag_system_ready = False
                        st.session_state.rag_chain = None
                        st.error(f"æ›´æ–°å¤±æ•—ï¼š{e}ã€‚è«‹ç¢ºèª Ollama æœå‹™æ­£åœ¨é‹è¡Œä¸”æ¨¡å‹å·²ä¸‹è¼‰ã€‚")
                        st.session_state.show_confirm_modal = False  # å‡ºéŒ¯æ™‚éš±è—æ–¹æ¡†
                        st.rerun()  # å¼·åˆ¶é‡æ–°åŸ·è¡Œä»¥æ›´æ–°UI
    with col_cancel:
        if st.button("å–æ¶ˆ", key="cancel_update_kb_button"):  # é»æ“Šã€Œå–æ¶ˆã€æŒ‰éˆ•
            st.session_state.show_confirm_modal = False  # éš±è—ç¢ºèªæ–¹æ¡†
            st.rerun()  # å¼·åˆ¶é‡æ–°åŸ·è¡Œä»¥æ›´æ–°UI
# endregion

# region --- é¡¯ç¤ºæ‘˜è¦å’Œé—œéµå­— ---
if st.session_state.rag_system_ready and (st.session_state.summary_output or st.session_state.keywords_output or st.session_state.questions_output):
    st.markdown("---")
    st.subheader("ğŸ’¡ çŸ¥è­˜åº«æ¦‚è¦½")

    if st.session_state.summary_output:
        st.markdown("### ğŸ” **é‡é»æ‘˜è¦**")
        highlighted_summary = highlight_important_tokens(st.session_state.summary_output, st.session_state.keywords_output)
        st.markdown(highlighted_summary, unsafe_allow_html=True)

    if st.session_state.keywords_output:
        st.markdown("### ğŸ”‘ **é—œéµå­—**")
        highlighted_keywords = highlight_important_tokens(st.session_state.keywords_output, st.session_state.keywords_output)
        st.markdown(highlighted_keywords, unsafe_allow_html=True)

    if st.session_state.questions_output:
        st.markdown("### â“ **ä½¿ç”¨è€…å¯èƒ½å¥½å¥‡çš„å•é¡Œ**")
        highlighted_questions = highlight_important_tokens(st.session_state.questions_output, st.session_state.keywords_output)
        st.markdown(highlighted_questions, unsafe_allow_html=True)
    st.markdown("---")
# endregion

# region --- èŠå¤©ä»‹é¢é‚è¼¯ ---
# é¡¯ç¤ºæ‰€æœ‰æ­·å²è¨Šæ¯ï¼Œå¦‚æœæ²’æœ‰é€™åŠŸèƒ½ï¼Œå‰‡åƒ…æœƒé¡¯ç¤ºæœ€æ–°å•ç­”å…§å®¹ !!
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if st.session_state.rag_system_ready:  # ç²å–ç”¨æˆ¶è¼¸å…¥ (åªæœ‰ç•¶ RAG ç³»çµ±å°±ç·’æ™‚æ‰å•Ÿç”¨è¼¸å…¥æ¡†)
    if not st.session_state.messages:  # åˆ¤æ–·æ˜¯å¦é¡¯ç¤ºé¦–æ¬¡å°è©±çš„åŠ©ç†æç¤ºè¨Šæ¯ (åƒ…åœ¨èŠå¤©æ­·å²ç‚ºç©ºä¸”åŠ©ç†å·²æº–å‚™å¥½æ™‚é¡¯ç¤º)
        initial_chat_message = "æ‚¨å¥½ï¼Œè«‹å•æœ‰ä»€éº¼æˆ‘å¯ä»¥å”åŠ©æ‚¨çš„ï¼Ÿ"
        with st.chat_message("assistant"):
            st.markdown(initial_chat_message)
            st.session_state.messages.append({"role": "assistant", "content": initial_chat_message})
    if prompt := st.chat_input("è¼¸å…¥æ‚¨çš„å•é¡Œ..."):  # å°‡ç”¨æˆ¶è¨Šæ¯æ·»åŠ åˆ°èŠå¤©æ­·å²ä¸¦é¡¯ç¤º (é ˆç•™æ„æ­¤æµ·è±¡ç¬¦è™Ÿç”¨æ³• !!!)
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        with st.chat_message("assistant"):  # ç²å– AI å›è¦†
            try:
                ai_response = st.session_state.rag_chain.invoke(prompt)  # é‡è¦!!! èª¿ç”¨ RAG éˆç²å–å›è¦†ã€‚
                st.markdown(ai_response)  # é¡¯ç¤ºæœ€çµ‚å›è¦†
            except Exception as e:
                error_message = f"å¾ˆæŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}ã€‚\nè«‹ç¢ºèª Ollama æœå‹™æ­£åœ¨é‹è¡Œã€‚"
                st.error(error_message)  # å°‡éŒ¯èª¤è¨Šæ¯ä½œç‚º AI å›è¦†
                ai_response = error_message  # ä¸‹ä¸€è¡Œå°‡ AI å›è¦†æ·»åŠ åˆ°èŠå¤©æ­·å²
            st.session_state.messages.append({"role": "assistant", "content": ai_response})
else:  # å¦‚æœ RAG ç³»çµ±å°šæœªå°±ç·’ï¼Œé¡¯ç¤ºæç¤ºè¨Šæ¯ä¸¦ç¦ç”¨èŠå¤©è¼¸å…¥æ¡†
    st.warning("è«‹å…ˆè¼¸å…¥æ‚¨çš„è³‡è¨Šä¸¦é»æ“Šã€Œåˆå§‹åŒ–/æ›´æ–°çŸ¥è­˜åº«ã€æŒ‰éˆ•ä¾†å•Ÿå‹•åŠ©ç†ã€‚")
    st.chat_input("è«‹å…ˆåˆå§‹åŒ–çŸ¥è­˜åº«...", disabled=True)


# endregion

# region --- å´æ¬„èªªæ˜ ---
st.sidebar.markdown("---")
st.sidebar.header("ä½¿ç”¨èªªæ˜")
st.sidebar.markdown("""
é€™å€‹æ‡‰ç”¨ç¨‹å¼æ˜¯ä¸€å€‹æ™ºèƒ½åŠ©ç†ï¼Œå®ƒæœƒ**å®Œå…¨æ ¹æ“šæ‚¨åœ¨æ–‡å­—å€åŸŸä¸­æä¾›çš„æœ€æ–°è³‡è¨Š**ä¾†å›ç­”å•é¡Œã€‚

**æ“ä½œæ­¥é©Ÿï¼š**
1.  åœ¨æ–‡å­—å€åŸŸä¸­**è¼¸å…¥æˆ–ä¿®æ”¹**æ‚¨çš„è³‡è¨Šã€‚
2.  **é‡è¦ï¼**
    * **ç¬¬ä¸€æ¬¡**é»æ“Šã€Œ**åˆå§‹åŒ–/æ›´æ–°çŸ¥è­˜åº«**ã€æŒ‰éˆ•ï¼Œå°‡æœƒè¼‰å…¥è³‡è¨Šä¸¦å•Ÿå‹•åŠ©ç†ã€‚
    * **å¾ŒçºŒ**é»æ“Šæ­¤æŒ‰éˆ•ï¼Œæœƒå½ˆå‡ºä¸€å€‹ç¢ºèªæ–¹æ¡†ï¼Œè©¢å•æ‚¨æ˜¯å¦è¦**æ›´æ–°**çŸ¥è­˜åº«ã€‚é»æ“Šã€Œç¢ºå®šæ›´æ–°ã€å°‡æœƒæ¸…é™¤èˆŠå°è©±ä¸¦ä½¿ç”¨æ–°è³‡è¨Šã€‚
3.  ç•¶çœ‹åˆ°ã€ŒğŸ‰ çŸ¥è­˜åº«èˆ‡ AI æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼ã€æˆ–ã€Œâœ… çŸ¥è­˜åº«å·²æˆåŠŸæ›´æ–°ï¼ã€è¨Šæ¯å¾Œï¼Œæ‚¨å°±å¯ä»¥åœ¨ä¸‹æ–¹çš„èŠå¤©æ¡†ä¸­æå•äº†ã€‚

**é‡è¦æé†’ï¼š**
è«‹ç¢ºä¿æ‚¨çš„é›»è…¦å·²**å®‰è£ Ollama æœå‹™**ä¸¦å·²**ä¸‹è¼‰ä»¥ä¸‹æ¨¡å‹**ï¼š
-   **åµŒå…¥æ¨¡å‹ (Embedding Model):** `nomic-embed-text`
    åŸ·è¡Œå‘½ä»¤ï¼š`ollama pull nomic-embed-text`
-   **èªè¨€æ¨¡å‹ (Language Model):** `llama3.2`
    åŸ·è¡Œå‘½ä»¤ï¼š`ollama pull llama3.2`

å°æ–¼çŸ¥è­˜åº«ä¸­æ²’æœ‰çš„è³‡è¨Šï¼ŒAI æœƒç¦®è²Œåœ°è¡¨ç¤ºç„¡æ³•å›ç­”ï¼Œä¸¦é¿å…ç·¨é€ å…§å®¹ã€‚
""")
# endregion